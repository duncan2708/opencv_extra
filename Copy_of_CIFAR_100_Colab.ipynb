{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CIFAR-100 Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/duncan2708/opencv_extra/blob/2.4/Copy_of_CIFAR_100_Colab.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "-SmJrhTsGo4K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using Colab for Image Classification with CIFAR-100"
      ]
    },
    {
      "metadata": {
        "id": "ed-8FUn2GqQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "emxEmraFoP3o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-BsjoNVqobjB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJvOo8gdopE_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cool. Both Tensorflow and Keras are already available with Colab. And, so are all these!"
      ]
    },
    {
      "metadata": {
        "id": "zjGrPhMmo03f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RSVKhR-3pmUI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btUOkX5iQhcp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('tf')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wkclEPv8p2vJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's try out hand at some bigger data than MNIST. \n",
        "\n",
        "**CIFAR-100** is a labeled subset of the 80 million Tiny Images dataset, and it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are also grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs)."
      ]
    },
    {
      "metadata": {
        "id": "VqJnDiA2rztS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://thkimorgblog.files.wordpress.com/2016/03/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2016-03-12-e1848be185a9e1848ce185a5e186ab-2-01-32.png?w=764\">"
      ]
    },
    {
      "metadata": {
        "id": "w4-BTgNLqfJZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting CIFAR100 from Keras"
      ]
    },
    {
      "metadata": {
        "id": "OF6FVTPpp0RT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar100\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16OZgmc4tAj-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's examine the data..."
      ]
    },
    {
      "metadata": {
        "id": "WtIj5nfjs__M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-CHOqsRotSU8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classidx = 0\n",
        "same_cat = x_train[[np.where(y_train==classidx)][0][0]]\n",
        "plt.imshow(same_cat[105, :, :, :])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4R5nrwr2x08b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In case you are wondering what are the class labels for classes 0 to 99, here are they..."
      ]
    },
    {
      "metadata": {
        "id": "4HeO0iV5tx6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CIFAR100_LABELS_LIST = [\n",
        "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
        "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
        "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
        "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
        "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
        "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
        "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
        "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
        "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
        "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
        "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
        "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
        "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
        "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
        "    'worm'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkYnJhLh0mx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "num_classes = 100\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VRQzvsY-s2EE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load and download other necessary stuff"
      ]
    },
    {
      "metadata": {
        "id": "n-P7BCIMs62r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLFnSnAly9FC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = applications.VGG16(include_top=False, weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZtEdfS51yAJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Put data through pre-trained model"
      ]
    },
    {
      "metadata": {
        "id": "VEeysVhS1mlW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KmOp_UV01wN1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bottleneck_features_train = model.predict(x_train, verbose=1 )\n",
        "np.save(open('vgg16_bottleneck_feats_train.npy', 'wb'), bottleneck_features_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kWsVZE7C7fWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bottleneck_features_test = model.predict(x_test, verbose=1 )\n",
        "np.save(open('vgg16_bottleneck_feats_test.npy', 'wb'), bottleneck_features_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "39IFpQGI2fsk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K9sSLn6X0HOU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ]
    },
    {
      "metadata": {
        "id": "UMN1pEiL2lG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = np.load(open('vgg16_bottleneck_feats_train.npy', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_jpz4pt3LSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "train_data = train_data[:,0,:,:]\n",
        "print(train_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vtNSqxw-0Gnk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf_model = Sequential()\n",
        "clf_model.add(Flatten(input_shape=(train_data.shape[1:])))\n",
        "clf_model.add(Dense(256, activation='relu'))\n",
        "clf_model.add(Dropout(0.5))\n",
        "clf_model.add(Dense(100, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyL8zLPM7M8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "batch_size = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SP_uUNDk28V4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LI0cu4En3Qd7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZTA2pRr9KlA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U22LxEGa44i6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data = np.load(open('vgg16_bottleneck_feats_test.npy', 'rb'))\n",
        "test_data = test_data[:,0,:,:]\n",
        "\n",
        "history = clf_model.fit(train_data, y_train, epochs=epochs, batch_size=batch_size, validation_data=(test_data, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jCxWUrvCIwFX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Did your validation accuracy cross 13% ?"
      ]
    },
    {
      "metadata": {
        "id": "nFUKnxLUJjNv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf_model.save('vgg_cifar100_fc_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "io940NlZLMV1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VFeb9SZ-HZba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Looking into the log"
      ]
    },
    {
      "metadata": {
        "id": "TRfBBiDNHd1I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8AUn7YTXHfdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JDj1LvgmHlXd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-oOCkCoJJEK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From your observation, what should be done next? "
      ]
    },
    {
      "metadata": {
        "id": "B_dJP_WBHu-t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning the model\n",
        "\n",
        "We should start by building the \"top\" end of the CNN. Let's consider the same classifier model we used previously."
      ]
    },
    {
      "metadata": {
        "id": "C1mTPgCDIS9Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-v8EFqGMze9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# now we should load the conv side from VGG16\n",
        "#from keras.engine.topology import Input\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "full_model = applications.VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wok1SXnKNq7G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add the classifier model after the VGG16 convolutional base\n",
        "clf_model = Sequential()\n",
        "clf_model.add(Flatten(input_shape=(train_data.shape[1:])))\n",
        "clf_model.add(Dense(256, activation='relu'))\n",
        "clf_model.add(Dropout(0.5))\n",
        "clf_model.add(Dense(100, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnSZgqcgM4o3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, so load the weights trained earlier back\n",
        "clf_model.load_weights('vgg_cifar100_fc_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LSl1D31QQEV6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add the classifier model on top of the convolutional base\n",
        "model = Sequential()\n",
        "model.add(full_model)\n",
        "model.add(clf_model)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpgcOvd2TC8N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.get_layer('vgg16').get_layer('block1_conv2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPgOJXP8XkCk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.layers[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RRxeon20X6o0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning the combined model"
      ]
    },
    {
      "metadata": {
        "id": "gPuqQ-vQUwTL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[0].layers[:25]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XkDYBcp1X-Fo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), metrics=['accuracy'])\n",
        "#model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5BglMy-YRHN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history2 = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXaZfG7acYtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show the accuracy and loss plots to further analyze the outcome of your training and validation."
      ]
    }
  ]
}